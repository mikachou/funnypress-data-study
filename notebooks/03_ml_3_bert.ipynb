{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2f5161b-e12c-4285-9f1e-d94ac4f0f530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 10:54:57.051416: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732442097.070527  188910 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732442097.076008  188910 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-24 10:54:57.094677: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, average_precision_score, make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import optuna\n",
    "\n",
    "from functions import *\n",
    "from bert_vectorizer import BertVectorizer\n",
    "\n",
    "import os\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"../data/clean/dataset.csv\").fillna('')\n",
    "X = df[\"title\"]\n",
    "y = df[\"funny\"]\n",
    "\n",
    "# Split into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c007096-7eb8-4158-800a-1f03da12b3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = BertVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14b9368b-a5f3-49e4-a87a-ec52b5acc53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1732442103.942215  188910 gpu_process_state.cc:201] Using CUDA malloc Async allocator for GPU: 0\n",
      "I0000 00:00:1732442103.942390  188910 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1730 MB memory:  -> device: 0, name: NVIDIA GeForce MX150, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFCamembertModel: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing TFCamembertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFCamembertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFCamembertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFCamembertModel for predictions without further training.\n",
      "Encoding Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 2665/2665 [17:28<00:00,  2.54it/s]\n",
      "Encoding Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 667/667 [04:24<00:00,  2.52it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_embeddings = vectorizer.fit_transform(list(X_train))\n",
    "X_test_embeddings = vectorizer.transform(list(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2476ad58-6b1c-48e3-9a8a-6e8f318675f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models\n",
    "best_models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc21ca24-b9d8-43e5-b580-b4e1ae8bffcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/code/python/funnypress-data-study/notebooks/functions.py:139: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  search = OptunaSearchCV(\n",
      "[I 2024-11-24 11:16:58,588] A new study created in memory with name: no-name-18102c59-91b1-4b1a-aba6-0c59547c953b\n",
      "[I 2024-11-24 11:20:11,724] Trial 3 finished with value: 0.2427933814796181 and parameters: {'classifier__n_estimators': 13, 'classifier__max_depth': 6, 'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 1}. Best is trial 3 with value: 0.2427933814796181.\n",
      "[I 2024-11-24 11:21:06,005] Trial 1 finished with value: 0.0 and parameters: {'classifier__n_estimators': 47, 'classifier__max_depth': 2, 'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 2}. Best is trial 3 with value: 0.2427933814796181.\n",
      "[I 2024-11-24 11:25:30,457] Trial 7 finished with value: 0.31686730965211224 and parameters: {'classifier__n_estimators': 31, 'classifier__max_depth': 7, 'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 1}. Best is trial 7 with value: 0.31686730965211224.\n",
      "[I 2024-11-24 11:25:55,239] Trial 8 finished with value: 0.0 and parameters: {'classifier__n_estimators': 67, 'classifier__max_depth': 2, 'classifier__min_samples_split': 3, 'classifier__min_samples_leaf': 1}. Best is trial 7 with value: 0.31686730965211224.\n",
      "[I 2024-11-24 11:27:09,425] Trial 4 finished with value: 0.0 and parameters: {'classifier__n_estimators': 81, 'classifier__max_depth': 3, 'classifier__min_samples_split': 4, 'classifier__min_samples_leaf': 1}. Best is trial 7 with value: 0.31686730965211224.\n",
      "[I 2024-11-24 11:27:30,882] Trial 11 finished with value: 0.0 and parameters: {'classifier__n_estimators': 13, 'classifier__max_depth': 3, 'classifier__min_samples_split': 4, 'classifier__min_samples_leaf': 1}. Best is trial 7 with value: 0.31686730965211224.\n",
      "[I 2024-11-24 11:28:51,019] Trial 5 finished with value: 0.39210082972164634 and parameters: {'classifier__n_estimators': 39, 'classifier__max_depth': 8, 'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 2}. Best is trial 5 with value: 0.39210082972164634.\n",
      "[I 2024-11-24 11:31:20,249] Trial 10 finished with value: 0.008685515278555331 and parameters: {'classifier__n_estimators': 37, 'classifier__max_depth': 4, 'classifier__min_samples_split': 2, 'classifier__min_samples_leaf': 2}. Best is trial 5 with value: 0.39210082972164634.\n",
      "[I 2024-11-24 11:35:23,826] Trial 0 finished with value: 0.07143944603181605 and parameters: {'classifier__n_estimators': 92, 'classifier__max_depth': 5, 'classifier__min_samples_split': 6, 'classifier__min_samples_leaf': 3}. Best is trial 5 with value: 0.39210082972164634.\n",
      "[I 2024-11-24 11:36:08,324] Trial 15 finished with value: 0.0 and parameters: {'classifier__n_estimators': 39, 'classifier__max_depth': 3, 'classifier__min_samples_split': 4, 'classifier__min_samples_leaf': 3}. Best is trial 5 with value: 0.39210082972164634.\n",
      "[I 2024-11-24 11:40:08,827] Trial 2 finished with value: 0.18724079139498903 and parameters: {'classifier__n_estimators': 100, 'classifier__max_depth': 6, 'classifier__min_samples_split': 3, 'classifier__min_samples_leaf': 2}. Best is trial 5 with value: 0.39210082972164634.\n",
      "[I 2024-11-24 11:44:00,351] Trial 6 finished with value: 0.38917567558061406 and parameters: {'classifier__n_estimators': 90, 'classifier__max_depth': 8, 'classifier__min_samples_split': 6, 'classifier__min_samples_leaf': 1}. Best is trial 5 with value: 0.39210082972164634.\n",
      "[I 2024-11-24 11:44:33,292] Trial 9 finished with value: 0.2986396156689014 and parameters: {'classifier__n_estimators': 88, 'classifier__max_depth': 7, 'classifier__min_samples_split': 3, 'classifier__min_samples_leaf': 1}. Best is trial 5 with value: 0.39210082972164634.\n",
      "[I 2024-11-24 11:44:33,954] Trial 13 finished with value: 0.38794528336164047 and parameters: {'classifier__n_estimators': 57, 'classifier__max_depth': 8, 'classifier__min_samples_split': 4, 'classifier__min_samples_leaf': 2}. Best is trial 5 with value: 0.39210082972164634.\n",
      "[I 2024-11-24 11:45:29,851] Trial 14 finished with value: 0.07108250766637704 and parameters: {'classifier__n_estimators': 86, 'classifier__max_depth': 5, 'classifier__min_samples_split': 2, 'classifier__min_samples_leaf': 1}. Best is trial 5 with value: 0.39210082972164634.\n",
      "[I 2024-11-24 11:47:35,399] Trial 18 finished with value: 0.3994845113771011 and parameters: {'classifier__n_estimators': 29, 'classifier__max_depth': 8, 'classifier__min_samples_split': 6, 'classifier__min_samples_leaf': 2}. Best is trial 18 with value: 0.3994845113771011.\n",
      "[I 2024-11-24 11:48:04,815] Trial 12 finished with value: 0.3911518034164965 and parameters: {'classifier__n_estimators': 74, 'classifier__max_depth': 8, 'classifier__min_samples_split': 6, 'classifier__min_samples_leaf': 2}. Best is trial 18 with value: 0.3994845113771011.\n",
      "[I 2024-11-24 11:50:37,690] Trial 16 finished with value: 0.3901746394553975 and parameters: {'classifier__n_estimators': 60, 'classifier__max_depth': 8, 'classifier__min_samples_split': 4, 'classifier__min_samples_leaf': 2}. Best is trial 18 with value: 0.3994845113771011.\n",
      "[I 2024-11-24 11:51:04,571] Trial 17 finished with value: 0.39359918431204816 and parameters: {'classifier__n_estimators': 62, 'classifier__max_depth': 8, 'classifier__min_samples_split': 6, 'classifier__min_samples_leaf': 2}. Best is trial 18 with value: 0.3994845113771011.\n",
      "[I 2024-11-24 11:54:33,815] Trial 19 finished with value: 0.39359918431204816 and parameters: {'classifier__n_estimators': 62, 'classifier__max_depth': 8, 'classifier__min_samples_split': 6, 'classifier__min_samples_leaf': 2}. Best is trial 18 with value: 0.3994845113771011.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__n_estimators': 29, 'classifier__max_depth': 8, 'classifier__min_samples_split': 6, 'classifier__min_samples_leaf': 2}\n",
      "Test Accuracy: 0.8595692769671093\n",
      "F1 Score: 0.4010406243746248\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92     17359\n",
      "           1       0.96      0.25      0.40      3954\n",
      "\n",
      "    accuracy                           0.86     21313\n",
      "   macro avg       0.91      0.63      0.66     21313\n",
      "weighted avg       0.87      0.86      0.82     21313\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf_param_distributions = {\n",
    "    \"classifier__n_estimators\": optuna.distributions.IntDistribution(10, 100),  # Fewer trees, as BERT embeddings are rich\n",
    "    \"classifier__max_depth\": optuna.distributions.IntDistribution(2, 8),       # Shallower trees due to high-dimensional data\n",
    "    \"classifier__min_samples_split\": optuna.distributions.IntDistribution(2, 6),\n",
    "    \"classifier__min_samples_leaf\": optuna.distributions.IntDistribution(1, 3),\n",
    "}\n",
    "\n",
    "rf_model, rf_acc = train_model_with_optuna(\n",
    "    model=RandomForestClassifier(random_state=314),\n",
    "    param_distributions=rf_param_distributions,\n",
    "    X_train_embeddings=X_train_embeddings,\n",
    "    y_train=y_train,\n",
    "    X_test_embeddings=X_test_embeddings,\n",
    "    y_test=y_test,\n",
    ")\n",
    "best_models.append((\"random_forest\", rf_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10c9b1f3-1d0e-4b14-ae33-50232030d1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/code/python/funnypress-data-study/notebooks/functions.py:139: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  search = OptunaSearchCV(\n",
      "[I 2024-11-24 11:55:31,513] A new study created in memory with name: no-name-d04841c6-cc8f-41a7-bbb3-04796a57317e\n",
      "[I 2024-11-24 11:58:24,918] Trial 6 finished with value: 0.04934040891365688 and parameters: {'classifier__n_estimators': 20, 'classifier__learning_rate': 0.07770109911706814, 'classifier__max_depth': 2, 'classifier__colsample_bytree': 0.7066701192503249, 'classifier__subsample': 0.8866915768004306}. Best is trial 6 with value: 0.04934040891365688.\n",
      "[I 2024-11-24 11:58:57,233] Trial 5 finished with value: 0.05267433991582621 and parameters: {'classifier__n_estimators': 21, 'classifier__learning_rate': 0.050942496335135, 'classifier__max_depth': 3, 'classifier__colsample_bytree': 0.5679596345597413, 'classifier__subsample': 0.8233998846384597}. Best is trial 5 with value: 0.05267433991582621.\n",
      "[I 2024-11-24 11:59:34,495] Trial 0 finished with value: 0.30758642506911305 and parameters: {'classifier__n_estimators': 20, 'classifier__learning_rate': 0.06454626471720823, 'classifier__max_depth': 4, 'classifier__colsample_bytree': 0.8596752986252797, 'classifier__subsample': 0.7488429576155322}. Best is trial 0 with value: 0.30758642506911305.\n",
      "[I 2024-11-24 11:59:34,981] Trial 1 finished with value: 0.3323324031937528 and parameters: {'classifier__n_estimators': 26, 'classifier__learning_rate': 0.07497024579833939, 'classifier__max_depth': 3, 'classifier__colsample_bytree': 0.5023804809814287, 'classifier__subsample': 0.7820985234129574}. Best is trial 1 with value: 0.3323324031937528.\n",
      "[I 2024-11-24 12:00:09,934] Trial 7 finished with value: 0.4309121832280411 and parameters: {'classifier__n_estimators': 25, 'classifier__learning_rate': 0.06836693437688718, 'classifier__max_depth': 4, 'classifier__colsample_bytree': 0.9128990825069419, 'classifier__subsample': 0.908703043959068}. Best is trial 7 with value: 0.4309121832280411.\n",
      "[I 2024-11-24 12:02:37,516] Trial 8 finished with value: 0.0505939048862311 and parameters: {'classifier__n_estimators': 45, 'classifier__learning_rate': 0.03702142901751962, 'classifier__max_depth': 2, 'classifier__colsample_bytree': 0.5372086695084581, 'classifier__subsample': 0.8470965794050411}. Best is trial 7 with value: 0.4309121832280411.\n",
      "[I 2024-11-24 12:03:31,533] Trial 4 finished with value: 0.36830799400189707 and parameters: {'classifier__n_estimators': 34, 'classifier__learning_rate': 0.03309636585427813, 'classifier__max_depth': 6, 'classifier__colsample_bytree': 0.5156841735221438, 'classifier__subsample': 0.9258967818187332}. Best is trial 7 with value: 0.4309121832280411.\n",
      "[I 2024-11-24 12:05:01,991] Trial 9 finished with value: 0.471931365203835 and parameters: {'classifier__n_estimators': 42, 'classifier__learning_rate': 0.047690068048009106, 'classifier__max_depth': 4, 'classifier__colsample_bytree': 0.651013789745171, 'classifier__subsample': 0.912341824694693}. Best is trial 9 with value: 0.471931365203835.\n",
      "[I 2024-11-24 12:07:51,797] Trial 12 finished with value: 0.34552523480996095 and parameters: {'classifier__n_estimators': 92, 'classifier__learning_rate': 0.035217169764074435, 'classifier__max_depth': 2, 'classifier__colsample_bytree': 0.7042361669851435, 'classifier__subsample': 0.6358481887236614}. Best is trial 9 with value: 0.471931365203835.\n",
      "[I 2024-11-24 12:07:57,972] Trial 3 finished with value: 0.6657266420795583 and parameters: {'classifier__n_estimators': 55, 'classifier__learning_rate': 0.048059667208493216, 'classifier__max_depth': 6, 'classifier__colsample_bytree': 0.7483183168796934, 'classifier__subsample': 0.6502796697875791}. Best is trial 3 with value: 0.6657266420795583.\n",
      "[I 2024-11-24 12:08:59,051] Trial 14 finished with value: 0.611085371292267 and parameters: {'classifier__n_estimators': 21, 'classifier__learning_rate': 0.09605900434422701, 'classifier__max_depth': 6, 'classifier__colsample_bytree': 0.8662086926852637, 'classifier__subsample': 0.9873963189821128}. Best is trial 3 with value: 0.6657266420795583.\n",
      "[I 2024-11-24 12:10:16,684] Trial 11 finished with value: 0.6446914168418422 and parameters: {'classifier__n_estimators': 61, 'classifier__learning_rate': 0.04619038558047581, 'classifier__max_depth': 5, 'classifier__colsample_bytree': 0.7677057562845748, 'classifier__subsample': 0.6427529181566992}. Best is trial 3 with value: 0.6657266420795583.\n",
      "[I 2024-11-24 12:10:49,975] Trial 2 finished with value: 0.0 and parameters: {'classifier__n_estimators': 94, 'classifier__learning_rate': 0.006075776558642424, 'classifier__max_depth': 5, 'classifier__colsample_bytree': 0.7205195747295516, 'classifier__subsample': 0.7776109012175779}. Best is trial 3 with value: 0.6657266420795583.\n",
      "[I 2024-11-24 12:10:58,232] Trial 13 finished with value: 0.7177352623488584 and parameters: {'classifier__n_estimators': 48, 'classifier__learning_rate': 0.09683063189328919, 'classifier__max_depth': 5, 'classifier__colsample_bytree': 0.6744349537742769, 'classifier__subsample': 0.7007499673844656}. Best is trial 13 with value: 0.7177352623488584.\n",
      "[I 2024-11-24 12:12:47,776] Trial 15 finished with value: 0.7051608609912218 and parameters: {'classifier__n_estimators': 78, 'classifier__learning_rate': 0.09782127959717685, 'classifier__max_depth': 3, 'classifier__colsample_bytree': 0.9242303078395452, 'classifier__subsample': 0.9714521251444639}. Best is trial 13 with value: 0.7177352623488584.\n",
      "[I 2024-11-24 12:16:00,668] Trial 10 finished with value: 0.7904204519365507 and parameters: {'classifier__n_estimators': 93, 'classifier__learning_rate': 0.09813426328744247, 'classifier__max_depth': 6, 'classifier__colsample_bytree': 0.7601857095940523, 'classifier__subsample': 0.756442032971816}. Best is trial 10 with value: 0.7904204519365507.\n",
      "[I 2024-11-24 12:16:24,137] Trial 16 finished with value: 0.6880064830499228 and parameters: {'classifier__n_estimators': 88, 'classifier__learning_rate': 0.0532907691799717, 'classifier__max_depth': 4, 'classifier__colsample_bytree': 0.7942091191843657, 'classifier__subsample': 0.8241330579156458}. Best is trial 10 with value: 0.7904204519365507.\n",
      "[I 2024-11-24 12:17:02,830] Trial 19 finished with value: 0.21310159018020586 and parameters: {'classifier__n_estimators': 63, 'classifier__learning_rate': 0.01515224199418206, 'classifier__max_depth': 5, 'classifier__colsample_bytree': 0.7973727995731444, 'classifier__subsample': 0.6047552280515972}. Best is trial 10 with value: 0.7904204519365507.\n",
      "[I 2024-11-24 12:17:27,844] Trial 17 finished with value: 0.12337950191580638 and parameters: {'classifier__n_estimators': 71, 'classifier__learning_rate': 0.010219422847333029, 'classifier__max_depth': 6, 'classifier__colsample_bytree': 0.8007728741167941, 'classifier__subsample': 0.600465079091252}. Best is trial 10 with value: 0.7904204519365507.\n",
      "[I 2024-11-24 12:17:34,961] Trial 18 finished with value: 0.06648011201713086 and parameters: {'classifier__n_estimators': 70, 'classifier__learning_rate': 0.009435059971138554, 'classifier__max_depth': 6, 'classifier__colsample_bytree': 0.8192449837677988, 'classifier__subsample': 0.9849715355801248}. Best is trial 10 with value: 0.7904204519365507.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__n_estimators': 93, 'classifier__learning_rate': 0.09813426328744247, 'classifier__max_depth': 6, 'classifier__colsample_bytree': 0.7601857095940523, 'classifier__subsample': 0.756442032971816}\n",
      "Test Accuracy: 0.9306995730305447\n",
      "F1 Score: 0.7968642552606244\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96     17359\n",
      "           1       0.87      0.73      0.80      3954\n",
      "\n",
      "    accuracy                           0.93     21313\n",
      "   macro avg       0.91      0.85      0.88     21313\n",
      "weighted avg       0.93      0.93      0.93     21313\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "xgb_param_distributions = {\n",
    "    \"classifier__n_estimators\": optuna.distributions.IntDistribution(20, 100),  # Fewer iterations needed\n",
    "    \"classifier__learning_rate\": optuna.distributions.FloatDistribution(0.005, 0.1),  # Lower range for stable learning\n",
    "    \"classifier__max_depth\": optuna.distributions.IntDistribution(2, 6),        # Shallower trees\n",
    "    \"classifier__colsample_bytree\": optuna.distributions.FloatDistribution(0.5, 1.0),  # Feature subsampling\n",
    "    \"classifier__subsample\": optuna.distributions.FloatDistribution(0.6, 1.0),  # Data subsampling\n",
    "}\n",
    "\n",
    "xgb_model, xgb_acc = train_model_with_optuna(\n",
    "    model=XGBClassifier(random_state=314),\n",
    "    param_distributions=xgb_param_distributions,\n",
    "    X_train_embeddings=X_train_embeddings,\n",
    "    y_train=y_train,\n",
    "    X_test_embeddings=X_test_embeddings,\n",
    "    y_test=y_test,\n",
    ")\n",
    "best_models.append((\"xgboost\", xgb_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae0c6d8f-0956-4c1b-a699-38ce383eeb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/code/python/funnypress-data-study/notebooks/functions.py:139: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  search = OptunaSearchCV(\n",
      "[I 2024-11-24 12:18:14,183] A new study created in memory with name: no-name-d103f0a0-7c48-470a-834d-24d9b427f359\n",
      "[I 2024-11-24 12:18:50,300] Trial 0 finished with value: 0.4418630605747177 and parameters: {'classifier__iterations': 83, 'classifier__learning_rate': 0.03521448296585186, 'classifier__depth': 3, 'classifier__l2_leaf_reg': 4.972089758671521}. Best is trial 0 with value: 0.4418630605747177.\n",
      "[I 2024-11-24 12:19:23,417] Trial 1 finished with value: 0.3790121111304335 and parameters: {'classifier__iterations': 97, 'classifier__learning_rate': 0.03930713913624876, 'classifier__depth': 2, 'classifier__l2_leaf_reg': 1.2103767928393903}. Best is trial 0 with value: 0.4418630605747177.\n",
      "[I 2024-11-24 12:19:47,653] Trial 2 finished with value: 0.3776194510499184 and parameters: {'classifier__iterations': 34, 'classifier__learning_rate': 0.04445319978181584, 'classifier__depth': 4, 'classifier__l2_leaf_reg': 2.252734192383126}. Best is trial 0 with value: 0.4418630605747177.\n",
      "[I 2024-11-24 12:20:16,951] Trial 3 finished with value: 0.43866912410709913 and parameters: {'classifier__iterations': 91, 'classifier__learning_rate': 0.05013034021852949, 'classifier__depth': 2, 'classifier__l2_leaf_reg': 1.6134402751884016}. Best is trial 0 with value: 0.4418630605747177.\n",
      "[I 2024-11-24 12:20:59,508] Trial 4 finished with value: 0.35052932360496725 and parameters: {'classifier__iterations': 62, 'classifier__learning_rate': 0.011455839667758773, 'classifier__depth': 5, 'classifier__l2_leaf_reg': 3.676531474422282}. Best is trial 0 with value: 0.4418630605747177.\n",
      "[I 2024-11-24 12:21:24,346] Trial 5 finished with value: 0.5504972154137662 and parameters: {'classifier__iterations': 49, 'classifier__learning_rate': 0.08644906745049194, 'classifier__depth': 3, 'classifier__l2_leaf_reg': 4.021570528524907}. Best is trial 5 with value: 0.5504972154137662.\n",
      "[I 2024-11-24 12:21:59,988] Trial 6 finished with value: 0.6763262240706542 and parameters: {'classifier__iterations': 86, 'classifier__learning_rate': 0.09566966860721653, 'classifier__depth': 3, 'classifier__l2_leaf_reg': 2.757083279029443}. Best is trial 6 with value: 0.6763262240706542.\n",
      "[I 2024-11-24 12:22:38,870] Trial 7 finished with value: 0.32186127178070845 and parameters: {'classifier__iterations': 75, 'classifier__learning_rate': 0.014798547789278041, 'classifier__depth': 4, 'classifier__l2_leaf_reg': 1.1166239033324623}. Best is trial 6 with value: 0.6763262240706542.\n",
      "[I 2024-11-24 12:23:08,604] Trial 8 finished with value: 0.6392110207132289 and parameters: {'classifier__iterations': 51, 'classifier__learning_rate': 0.09147260511313139, 'classifier__depth': 4, 'classifier__l2_leaf_reg': 2.837229208035374}. Best is trial 6 with value: 0.6763262240706542.\n",
      "[I 2024-11-24 12:23:40,302] Trial 9 finished with value: 0.4619256237743201 and parameters: {'classifier__iterations': 30, 'classifier__learning_rate': 0.03549667917197551, 'classifier__depth': 6, 'classifier__l2_leaf_reg': 2.8661054601145843}. Best is trial 6 with value: 0.6763262240706542.\n",
      "[I 2024-11-24 12:24:11,560] Trial 10 finished with value: 0.6009734503819738 and parameters: {'classifier__iterations': 74, 'classifier__learning_rate': 0.06983637917642325, 'classifier__depth': 3, 'classifier__l2_leaf_reg': 2.2142350435498157}. Best is trial 6 with value: 0.6763262240706542.\n",
      "[I 2024-11-24 12:24:50,180] Trial 11 finished with value: 0.6868454720515957 and parameters: {'classifier__iterations': 55, 'classifier__learning_rate': 0.0918759451936913, 'classifier__depth': 5, 'classifier__l2_leaf_reg': 2.8498621122101}. Best is trial 11 with value: 0.6868454720515957.\n",
      "[I 2024-11-24 12:25:41,691] Trial 12 finished with value: 0.690737074078898 and parameters: {'classifier__iterations': 59, 'classifier__learning_rate': 0.07516982680468555, 'classifier__depth': 6, 'classifier__l2_leaf_reg': 3.573956258642671}. Best is trial 12 with value: 0.690737074078898.\n",
      "[I 2024-11-24 12:26:31,081] Trial 13 finished with value: 0.6696158045597841 and parameters: {'classifier__iterations': 56, 'classifier__learning_rate': 0.06750278443777788, 'classifier__depth': 6, 'classifier__l2_leaf_reg': 3.6964400458893834}. Best is trial 12 with value: 0.690737074078898.\n",
      "[I 2024-11-24 12:27:03,463] Trial 14 finished with value: 0.6060935371156442 and parameters: {'classifier__iterations': 42, 'classifier__learning_rate': 0.0744952850635602, 'classifier__depth': 5, 'classifier__l2_leaf_reg': 4.327842967390318}. Best is trial 12 with value: 0.690737074078898.\n",
      "[I 2024-11-24 12:27:48,070] Trial 15 finished with value: 0.6923686740458513 and parameters: {'classifier__iterations': 67, 'classifier__learning_rate': 0.08067913230594767, 'classifier__depth': 5, 'classifier__l2_leaf_reg': 3.355148516980317}. Best is trial 15 with value: 0.6923686740458513.\n",
      "[I 2024-11-24 12:28:46,835] Trial 16 finished with value: 0.6877031540318269 and parameters: {'classifier__iterations': 69, 'classifier__learning_rate': 0.06242014131003854, 'classifier__depth': 6, 'classifier__l2_leaf_reg': 3.439432932941059}. Best is trial 15 with value: 0.6923686740458513.\n",
      "[I 2024-11-24 12:29:28,697] Trial 17 finished with value: 0.6823497907127721 and parameters: {'classifier__iterations': 62, 'classifier__learning_rate': 0.08023783074191529, 'classifier__depth': 5, 'classifier__l2_leaf_reg': 4.544304306090354}. Best is trial 15 with value: 0.6923686740458513.\n",
      "[I 2024-11-24 12:30:26,380] Trial 18 finished with value: 0.6734482806891927 and parameters: {'classifier__iterations': 68, 'classifier__learning_rate': 0.05748450193059418, 'classifier__depth': 6, 'classifier__l2_leaf_reg': 3.2674663689006085}. Best is trial 15 with value: 0.6923686740458513.\n",
      "[I 2024-11-24 12:30:59,427] Trial 19 finished with value: 0.6228867100821165 and parameters: {'classifier__iterations': 43, 'classifier__learning_rate': 0.07894571138211429, 'classifier__depth': 5, 'classifier__l2_leaf_reg': 2.2860364212049182}. Best is trial 15 with value: 0.6923686740458513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__iterations': 67, 'classifier__learning_rate': 0.08067913230594767, 'classifier__depth': 5, 'classifier__l2_leaf_reg': 3.355148516980317}\n",
      "Test Accuracy: 0.9080373480974053\n",
      "F1 Score: 0.7017650639074863\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.95     17359\n",
      "           1       0.88      0.58      0.70      3954\n",
      "\n",
      "    accuracy                           0.91     21313\n",
      "   macro avg       0.90      0.78      0.82     21313\n",
      "weighted avg       0.91      0.91      0.90     21313\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CatBoost\n",
    "catboost_param_distributions = {\n",
    "    \"classifier__iterations\": optuna.distributions.IntDistribution(30, 100),    # Fewer iterations\n",
    "    \"classifier__learning_rate\": optuna.distributions.FloatDistribution(0.005, 0.1),  # Smaller learning rates\n",
    "    \"classifier__depth\": optuna.distributions.IntDistribution(2, 6),            # Shallower trees\n",
    "    \"classifier__l2_leaf_reg\": optuna.distributions.FloatDistribution(1, 5),    # Regularization strength\n",
    "}\n",
    "\n",
    "catboost_model, catboost_acc = train_model_with_optuna(\n",
    "    model=CatBoostClassifier(verbose=0, random_state=314),\n",
    "    param_distributions=catboost_param_distributions,\n",
    "    X_train_embeddings=X_train_embeddings,\n",
    "    y_train=y_train,\n",
    "    X_test_embeddings=X_test_embeddings,\n",
    "    y_test=y_test,\n",
    "    n_jobs=1,\n",
    ")\n",
    "best_models.append((\"catboost\", catboost_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf053c75-cc3a-4b62-a136-5fa0b8a52bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier Test Accuracy: 0.9322948435227326\n",
      "Stacking Classifier F1 Score: 0.8099565389174239\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96     17359\n",
      "           1       0.85      0.78      0.81      3954\n",
      "\n",
      "    accuracy                           0.93     21313\n",
      "   macro avg       0.90      0.87      0.88     21313\n",
      "weighted avg       0.93      0.93      0.93     21313\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stacking the best models\n",
    "stacked_classifier = StackingClassifier(\n",
    "    estimators=best_models,\n",
    "    final_estimator=GradientBoostingClassifier(random_state=314),\n",
    "    cv=5,\n",
    ")\n",
    "\n",
    "\n",
    "stacked_classifier.fit(X_train_embeddings, y_train)\n",
    "y_pred = stacked_classifier.predict(X_test_embeddings)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Stacking Classifier Test Accuracy: {acc}\")\n",
    "print(f\"Stacking Classifier F1 Score: {f1}\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2caa3fe-912f-4b07-a81d-c2d8bf4120f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
