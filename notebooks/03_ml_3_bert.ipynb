{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2f5161b-e12c-4285-9f1e-d94ac4f0f530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-23 20:35:07.050833: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732390507.069873   87832 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732390507.076462   87832 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-23 20:35:07.094676: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, average_precision_score, make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import optuna\n",
    "\n",
    "from functions import *\n",
    "from bert_vectorizer import BertVectorizer\n",
    "\n",
    "import os\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"../data/clean/dataset.csv\").fillna('')\n",
    "X = df[\"lemmes\"]\n",
    "y = df[\"funny\"]\n",
    "\n",
    "# Split into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c007096-7eb8-4158-800a-1f03da12b3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = BertVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14b9368b-a5f3-49e4-a87a-ec52b5acc53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1732390510.869617   87832 gpu_process_state.cc:201] Using CUDA malloc Async allocator for GPU: 0\n",
      "I0000 00:00:1732390510.869794   87832 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1730 MB memory:  -> device: 0, name: NVIDIA GeForce MX150, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFCamembertModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing TFCamembertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFCamembertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFCamembertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFCamembertModel for predictions without further training.\n",
      "Encoding Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 2665/2665 [13:55<00:00,  3.19it/s]\n",
      "Encoding Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 667/667 [03:40<00:00,  3.02it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_embeddings = vectorizer.fit_transform(list(X_train))\n",
    "X_test_embeddings = vectorizer.transform(list(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2476ad58-6b1c-48e3-9a8a-6e8f318675f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models\n",
    "best_models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc21ca24-b9d8-43e5-b580-b4e1ae8bffcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/code/python/funnypress-data-study/notebooks/functions.py:139: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  search = OptunaSearchCV(\n",
      "[I 2024-11-23 20:52:48,809] A new study created in memory with name: no-name-873a67e1-94f4-4247-aae9-ca819cb70e5d\n",
      "[I 2024-11-23 20:56:31,341] Trial 7 finished with value: 0.11481926902053194 and parameters: {'classifier__n_estimators': 12, 'classifier__max_depth': 8, 'classifier__min_samples_split': 6, 'classifier__min_samples_leaf': 1}. Best is trial 7 with value: 0.11481926902053194.\n",
      "[I 2024-11-23 20:58:17,829] Trial 0 finished with value: 0.0 and parameters: {'classifier__n_estimators': 33, 'classifier__max_depth': 4, 'classifier__min_samples_split': 4, 'classifier__min_samples_leaf': 1}. Best is trial 7 with value: 0.11481926902053194.\n",
      "[I 2024-11-23 20:58:33,047] Trial 4 finished with value: 0.06254138603729431 and parameters: {'classifier__n_estimators': 21, 'classifier__max_depth': 7, 'classifier__min_samples_split': 4, 'classifier__min_samples_leaf': 1}. Best is trial 7 with value: 0.11481926902053194.\n",
      "[I 2024-11-23 20:59:13,676] Trial 5 finished with value: 0.06137849151261876 and parameters: {'classifier__n_estimators': 23, 'classifier__max_depth': 7, 'classifier__min_samples_split': 3, 'classifier__min_samples_leaf': 1}. Best is trial 7 with value: 0.11481926902053194.\n",
      "[I 2024-11-23 21:02:04,998] Trial 10 finished with value: 0.07281441564225369 and parameters: {'classifier__n_estimators': 13, 'classifier__max_depth': 7, 'classifier__min_samples_split': 2, 'classifier__min_samples_leaf': 2}. Best is trial 7 with value: 0.11481926902053194.\n",
      "[I 2024-11-23 21:04:04,803] Trial 9 finished with value: 0.06433981813831871 and parameters: {'classifier__n_estimators': 21, 'classifier__max_depth': 7, 'classifier__min_samples_split': 2, 'classifier__min_samples_leaf': 2}. Best is trial 7 with value: 0.11481926902053194.\n",
      "[I 2024-11-23 21:04:32,510] Trial 11 finished with value: 0.0022735652608480658 and parameters: {'classifier__n_estimators': 27, 'classifier__max_depth': 5, 'classifier__min_samples_split': 3, 'classifier__min_samples_leaf': 1}. Best is trial 7 with value: 0.11481926902053194.\n",
      "[I 2024-11-23 21:05:00,520] Trial 1 finished with value: 0.05322219958254665 and parameters: {'classifier__n_estimators': 45, 'classifier__max_depth': 7, 'classifier__min_samples_split': 6, 'classifier__min_samples_leaf': 2}. Best is trial 7 with value: 0.11481926902053194.\n",
      "[I 2024-11-23 21:05:20,526] Trial 2 finished with value: 0.05357865448016948 and parameters: {'classifier__n_estimators': 46, 'classifier__max_depth': 7, 'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 3}. Best is trial 7 with value: 0.11481926902053194.\n",
      "[I 2024-11-23 21:06:39,087] Trial 6 finished with value: 0.022249452915660512 and parameters: {'classifier__n_estimators': 58, 'classifier__max_depth': 6, 'classifier__min_samples_split': 4, 'classifier__min_samples_leaf': 2}. Best is trial 7 with value: 0.11481926902053194.\n",
      "[I 2024-11-23 21:08:08,617] Trial 13 finished with value: 0.025196345171502387 and parameters: {'classifier__n_estimators': 17, 'classifier__max_depth': 6, 'classifier__min_samples_split': 4, 'classifier__min_samples_leaf': 1}. Best is trial 7 with value: 0.11481926902053194.\n",
      "[I 2024-11-23 21:08:57,661] Trial 3 finished with value: 0.053949486382982983 and parameters: {'classifier__n_estimators': 59, 'classifier__max_depth': 7, 'classifier__min_samples_split': 3, 'classifier__min_samples_leaf': 1}. Best is trial 7 with value: 0.11481926902053194.\n",
      "[I 2024-11-23 21:09:35,961] Trial 14 finished with value: 0.026557337932030235 and parameters: {'classifier__n_estimators': 21, 'classifier__max_depth': 6, 'classifier__min_samples_split': 3, 'classifier__min_samples_leaf': 2}. Best is trial 7 with value: 0.11481926902053194.\n",
      "[I 2024-11-23 21:13:51,072] Trial 17 finished with value: 0.0 and parameters: {'classifier__n_estimators': 87, 'classifier__max_depth': 2, 'classifier__min_samples_split': 6, 'classifier__min_samples_leaf': 3}. Best is trial 7 with value: 0.11481926902053194.\n",
      "[I 2024-11-23 21:15:30,969] Trial 18 finished with value: 0.0 and parameters: {'classifier__n_estimators': 94, 'classifier__max_depth': 2, 'classifier__min_samples_split': 6, 'classifier__min_samples_leaf': 3}. Best is trial 7 with value: 0.11481926902053194.\n",
      "[I 2024-11-23 21:15:52,241] Trial 19 finished with value: 0.0 and parameters: {'classifier__n_estimators': 89, 'classifier__max_depth': 2, 'classifier__min_samples_split': 6, 'classifier__min_samples_leaf': 3}. Best is trial 7 with value: 0.11481926902053194.\n",
      "[I 2024-11-23 21:16:54,908] Trial 8 finished with value: 0.019530881721553827 and parameters: {'classifier__n_estimators': 92, 'classifier__max_depth': 6, 'classifier__min_samples_split': 3, 'classifier__min_samples_leaf': 1}. Best is trial 7 with value: 0.11481926902053194.\n",
      "[I 2024-11-23 21:18:10,635] Trial 15 finished with value: 0.0011374808283456665 and parameters: {'classifier__n_estimators': 77, 'classifier__max_depth': 5, 'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 3}. Best is trial 7 with value: 0.11481926902053194.\n",
      "[I 2024-11-23 21:19:01,107] Trial 12 finished with value: 0.05395976794163045 and parameters: {'classifier__n_estimators': 74, 'classifier__max_depth': 7, 'classifier__min_samples_split': 2, 'classifier__min_samples_leaf': 1}. Best is trial 7 with value: 0.11481926902053194.\n",
      "[I 2024-11-23 21:20:57,290] Trial 16 finished with value: 0.09462557788741251 and parameters: {'classifier__n_estimators': 68, 'classifier__max_depth': 8, 'classifier__min_samples_split': 4, 'classifier__min_samples_leaf': 1}. Best is trial 7 with value: 0.11481926902053194.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__n_estimators': 12, 'classifier__max_depth': 8, 'classifier__min_samples_split': 6, 'classifier__min_samples_leaf': 1}\n",
      "Test Accuracy: 0.8246140853000516\n",
      "F1 Score: 0.11589403973509933\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90     17359\n",
      "           1       0.89      0.06      0.12      3954\n",
      "\n",
      "    accuracy                           0.82     21313\n",
      "   macro avg       0.86      0.53      0.51     21313\n",
      "weighted avg       0.84      0.82      0.76     21313\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf_param_distributions = {\n",
    "    \"classifier__n_estimators\": optuna.distributions.IntDistribution(10, 100),  # Fewer trees, as BERT embeddings are rich\n",
    "    \"classifier__max_depth\": optuna.distributions.IntDistribution(2, 8),       # Shallower trees due to high-dimensional data\n",
    "    \"classifier__min_samples_split\": optuna.distributions.IntDistribution(2, 6),\n",
    "    \"classifier__min_samples_leaf\": optuna.distributions.IntDistribution(1, 3),\n",
    "}\n",
    "\n",
    "rf_model, rf_acc = train_model_with_optuna(\n",
    "    model=RandomForestClassifier(random_state=314),\n",
    "    param_distributions=rf_param_distributions,\n",
    "    X_train_embeddings=X_train_embeddings,\n",
    "    y_train=y_train,\n",
    "    X_test_embeddings=X_test_embeddings,\n",
    "    y_test=y_test,\n",
    ")\n",
    "best_models.append((\"random_forest\", rf_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10c9b1f3-1d0e-4b14-ae33-50232030d1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/code/python/funnypress-data-study/notebooks/functions.py:139: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  search = OptunaSearchCV(\n",
      "[I 2024-11-23 21:21:23,154] A new study created in memory with name: no-name-7ee120cf-12ce-4231-8b32-3fafcd2991d1\n",
      "[I 2024-11-23 21:25:12,781] Trial 5 finished with value: 0.0 and parameters: {'classifier__n_estimators': 36, 'classifier__learning_rate': 0.03023514612054874, 'classifier__max_depth': 2, 'classifier__colsample_bytree': 0.9147813859093016, 'classifier__subsample': 0.8513104449884434}. Best is trial 5 with value: 0.0.\n",
      "[I 2024-11-23 21:28:27,985] Trial 1 finished with value: 0.2574936982788675 and parameters: {'classifier__n_estimators': 27, 'classifier__learning_rate': 0.06011312358127173, 'classifier__max_depth': 6, 'classifier__colsample_bytree': 0.9087404424905497, 'classifier__subsample': 0.641903183543874}. Best is trial 1 with value: 0.2574936982788675.\n",
      "[I 2024-11-23 21:28:55,358] Trial 2 finished with value: 0.3531095113708773 and parameters: {'classifier__n_estimators': 51, 'classifier__learning_rate': 0.07106992674172187, 'classifier__max_depth': 4, 'classifier__colsample_bytree': 0.8508718438212404, 'classifier__subsample': 0.7145901611535822}. Best is trial 2 with value: 0.3531095113708773.\n",
      "[I 2024-11-23 21:30:11,679] Trial 0 finished with value: 0.083412436376308 and parameters: {'classifier__n_estimators': 39, 'classifier__learning_rate': 0.026828151350050386, 'classifier__max_depth': 6, 'classifier__colsample_bytree': 0.5172460541744024, 'classifier__subsample': 0.95649205354819}. Best is trial 2 with value: 0.3531095113708773.\n",
      "[I 2024-11-23 21:30:32,863] Trial 8 finished with value: 0.3087693837169422 and parameters: {'classifier__n_estimators': 47, 'classifier__learning_rate': 0.09085884647480898, 'classifier__max_depth': 3, 'classifier__colsample_bytree': 0.5154486356093029, 'classifier__subsample': 0.8289597996593246}. Best is trial 2 with value: 0.3531095113708773.\n",
      "[I 2024-11-23 21:32:35,860] Trial 9 finished with value: 0.2295408161019338 and parameters: {'classifier__n_estimators': 23, 'classifier__learning_rate': 0.0921195832949096, 'classifier__max_depth': 4, 'classifier__colsample_bytree': 0.8410394098813643, 'classifier__subsample': 0.7322004479761399}. Best is trial 2 with value: 0.3531095113708773.\n",
      "[I 2024-11-23 21:32:59,678] Trial 6 finished with value: 0.24346639037084125 and parameters: {'classifier__n_estimators': 84, 'classifier__learning_rate': 0.02900513364618376, 'classifier__max_depth': 4, 'classifier__colsample_bytree': 0.7622949985798222, 'classifier__subsample': 0.9764505887961844}. Best is trial 2 with value: 0.3531095113708773.\n",
      "[I 2024-11-23 21:35:38,911] Trial 4 finished with value: 0.0 and parameters: {'classifier__n_estimators': 85, 'classifier__learning_rate': 0.0070291126588602395, 'classifier__max_depth': 5, 'classifier__colsample_bytree': 0.5350217708175609, 'classifier__subsample': 0.8900272819909363}. Best is trial 2 with value: 0.3531095113708773.\n",
      "[I 2024-11-23 21:35:44,536] Trial 10 finished with value: 0.38386851939027544 and parameters: {'classifier__n_estimators': 37, 'classifier__learning_rate': 0.09074591663956294, 'classifier__max_depth': 5, 'classifier__colsample_bytree': 0.68804562034499, 'classifier__subsample': 0.8802026028605023}. Best is trial 10 with value: 0.38386851939027544.\n",
      "[I 2024-11-23 21:36:26,739] Trial 7 finished with value: 0.05007498979171095 and parameters: {'classifier__n_estimators': 84, 'classifier__learning_rate': 0.010901594970473851, 'classifier__max_depth': 5, 'classifier__colsample_bytree': 0.9414577641608118, 'classifier__subsample': 0.834021718526207}. Best is trial 10 with value: 0.38386851939027544.\n",
      "[I 2024-11-23 21:37:57,572] Trial 13 finished with value: 0.0 and parameters: {'classifier__n_estimators': 34, 'classifier__learning_rate': 0.021541333563372036, 'classifier__max_depth': 4, 'classifier__colsample_bytree': 0.9063599740880564, 'classifier__subsample': 0.7575255496251323}. Best is trial 10 with value: 0.38386851939027544.\n",
      "[I 2024-11-23 21:38:41,773] Trial 12 finished with value: 0.3902579100962911 and parameters: {'classifier__n_estimators': 76, 'classifier__learning_rate': 0.08016665922038695, 'classifier__max_depth': 3, 'classifier__colsample_bytree': 0.8728049164091914, 'classifier__subsample': 0.6766413804741352}. Best is trial 12 with value: 0.3902579100962911.\n",
      "[I 2024-11-23 21:38:55,357] Trial 3 finished with value: 0.5193876536520893 and parameters: {'classifier__n_estimators': 78, 'classifier__learning_rate': 0.0792971615767501, 'classifier__max_depth': 6, 'classifier__colsample_bytree': 0.8982245261346242, 'classifier__subsample': 0.6470931857429583}. Best is trial 3 with value: 0.5193876536520893.\n",
      "[I 2024-11-23 21:41:53,797] Trial 16 finished with value: 0.31934224653188287 and parameters: {'classifier__n_estimators': 58, 'classifier__learning_rate': 0.07255868190190513, 'classifier__max_depth': 3, 'classifier__colsample_bytree': 0.9771383156531301, 'classifier__subsample': 0.662348042937317}. Best is trial 3 with value: 0.5193876536520893.\n",
      "[I 2024-11-23 21:42:04,174] Trial 14 finished with value: 0.2964644305535268 and parameters: {'classifier__n_estimators': 41, 'classifier__learning_rate': 0.04685542320174333, 'classifier__max_depth': 6, 'classifier__colsample_bytree': 0.9094086774550207, 'classifier__subsample': 0.8615686607737398}. Best is trial 3 with value: 0.5193876536520893.\n",
      "[I 2024-11-23 21:43:14,035] Trial 19 finished with value: 0.26027238768109345 and parameters: {'classifier__n_estimators': 69, 'classifier__learning_rate': 0.07906003340443676, 'classifier__max_depth': 2, 'classifier__colsample_bytree': 0.6613939393426043, 'classifier__subsample': 0.6022695620815887}. Best is trial 3 with value: 0.5193876536520893.\n",
      "[I 2024-11-23 21:44:47,281] Trial 17 finished with value: 0.4509670619074428 and parameters: {'classifier__n_estimators': 66, 'classifier__learning_rate': 0.07536603930336694, 'classifier__max_depth': 5, 'classifier__colsample_bytree': 0.6423651342581403, 'classifier__subsample': 0.9185848309365116}. Best is trial 3 with value: 0.5193876536520893.\n",
      "[I 2024-11-23 21:45:00,093] Trial 18 finished with value: 0.42695887922696496 and parameters: {'classifier__n_estimators': 60, 'classifier__learning_rate': 0.06984315815023691, 'classifier__max_depth': 5, 'classifier__colsample_bytree': 0.713276229194997, 'classifier__subsample': 0.6794436616071715}. Best is trial 3 with value: 0.5193876536520893.\n",
      "[I 2024-11-23 21:45:28,787] Trial 11 finished with value: 0.5025789635924746 and parameters: {'classifier__n_estimators': 92, 'classifier__learning_rate': 0.06234011108364653, 'classifier__max_depth': 6, 'classifier__colsample_bytree': 0.9214211983535805, 'classifier__subsample': 0.8830511486088292}. Best is trial 3 with value: 0.5193876536520893.\n",
      "[I 2024-11-23 21:45:57,889] Trial 15 finished with value: 0.478996669157892 and parameters: {'classifier__n_estimators': 87, 'classifier__learning_rate': 0.0553951697243427, 'classifier__max_depth': 6, 'classifier__colsample_bytree': 0.7699165618900863, 'classifier__subsample': 0.9645363553685219}. Best is trial 3 with value: 0.5193876536520893.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__n_estimators': 78, 'classifier__learning_rate': 0.0792971615767501, 'classifier__max_depth': 6, 'classifier__colsample_bytree': 0.8982245261346242, 'classifier__subsample': 0.6470931857429583}\n",
      "Test Accuracy: 0.8643081687233144\n",
      "F1 Score: 0.5176784523015343\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92     17359\n",
      "           1       0.76      0.39      0.52      3954\n",
      "\n",
      "    accuracy                           0.86     21313\n",
      "   macro avg       0.82      0.68      0.72     21313\n",
      "weighted avg       0.85      0.86      0.85     21313\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "xgb_param_distributions = {\n",
    "    \"classifier__n_estimators\": optuna.distributions.IntDistribution(20, 100),  # Fewer iterations needed\n",
    "    \"classifier__learning_rate\": optuna.distributions.FloatDistribution(0.005, 0.1),  # Lower range for stable learning\n",
    "    \"classifier__max_depth\": optuna.distributions.IntDistribution(2, 6),        # Shallower trees\n",
    "    \"classifier__colsample_bytree\": optuna.distributions.FloatDistribution(0.5, 1.0),  # Feature subsampling\n",
    "    \"classifier__subsample\": optuna.distributions.FloatDistribution(0.6, 1.0),  # Data subsampling\n",
    "}\n",
    "\n",
    "xgb_model, xgb_acc = train_model_with_optuna(\n",
    "    model=XGBClassifier(random_state=314),\n",
    "    param_distributions=xgb_param_distributions,\n",
    "    X_train_embeddings=X_train_embeddings,\n",
    "    y_train=y_train,\n",
    "    X_test_embeddings=X_test_embeddings,\n",
    "    y_test=y_test,\n",
    ")\n",
    "best_models.append((\"xgboost\", xgb_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae0c6d8f-0956-4c1b-a699-38ce383eeb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/code/python/funnypress-data-study/notebooks/functions.py:139: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  search = OptunaSearchCV(\n",
      "[I 2024-11-23 21:46:31,749] A new study created in memory with name: no-name-9a390985-4573-4ed0-9a3c-06fce11c9c44\n",
      "[I 2024-11-23 21:47:06,599] Trial 0 finished with value: 0.16452283357240993 and parameters: {'classifier__iterations': 83, 'classifier__learning_rate': 0.03521448296585186, 'classifier__depth': 3, 'classifier__l2_leaf_reg': 4.972089758671521}. Best is trial 0 with value: 0.16452283357240993.\n",
      "[I 2024-11-23 21:47:35,984] Trial 1 finished with value: 0.12730055383823205 and parameters: {'classifier__iterations': 97, 'classifier__learning_rate': 0.03930713913624876, 'classifier__depth': 2, 'classifier__l2_leaf_reg': 1.2103767928393903}. Best is trial 0 with value: 0.16452283357240993.\n",
      "[I 2024-11-23 21:48:00,006] Trial 2 finished with value: 0.12488524256369551 and parameters: {'classifier__iterations': 34, 'classifier__learning_rate': 0.04445319978181584, 'classifier__depth': 4, 'classifier__l2_leaf_reg': 2.252734192383126}. Best is trial 0 with value: 0.16452283357240993.\n",
      "[I 2024-11-23 21:48:28,535] Trial 3 finished with value: 0.17519520568499988 and parameters: {'classifier__iterations': 91, 'classifier__learning_rate': 0.05013034021852949, 'classifier__depth': 2, 'classifier__l2_leaf_reg': 1.6134402751884016}. Best is trial 3 with value: 0.17519520568499988.\n",
      "[I 2024-11-23 21:49:09,511] Trial 4 finished with value: 0.08966842123346516 and parameters: {'classifier__iterations': 62, 'classifier__learning_rate': 0.011455839667758773, 'classifier__depth': 5, 'classifier__l2_leaf_reg': 3.676531474422282}. Best is trial 3 with value: 0.17519520568499988.\n",
      "[I 2024-11-23 21:49:33,424] Trial 5 finished with value: 0.25738540426455725 and parameters: {'classifier__iterations': 49, 'classifier__learning_rate': 0.08644906745049194, 'classifier__depth': 3, 'classifier__l2_leaf_reg': 4.021570528524907}. Best is trial 5 with value: 0.25738540426455725.\n",
      "[I 2024-11-23 21:50:07,365] Trial 6 finished with value: 0.38764595005382596 and parameters: {'classifier__iterations': 86, 'classifier__learning_rate': 0.09566966860721653, 'classifier__depth': 3, 'classifier__l2_leaf_reg': 2.757083279029443}. Best is trial 6 with value: 0.38764595005382596.\n",
      "[I 2024-11-23 21:50:45,559] Trial 7 finished with value: 0.08274457120407323 and parameters: {'classifier__iterations': 75, 'classifier__learning_rate': 0.014798547789278041, 'classifier__depth': 4, 'classifier__l2_leaf_reg': 1.1166239033324623}. Best is trial 6 with value: 0.38764595005382596.\n",
      "[I 2024-11-23 21:51:15,802] Trial 8 finished with value: 0.3361876740048266 and parameters: {'classifier__iterations': 51, 'classifier__learning_rate': 0.09147260511313139, 'classifier__depth': 4, 'classifier__l2_leaf_reg': 2.837229208035374}. Best is trial 6 with value: 0.38764595005382596.\n",
      "[I 2024-11-23 21:51:48,284] Trial 9 finished with value: 0.16436654105347218 and parameters: {'classifier__iterations': 30, 'classifier__learning_rate': 0.03549667917197551, 'classifier__depth': 6, 'classifier__l2_leaf_reg': 2.8661054601145843}. Best is trial 6 with value: 0.38764595005382596.\n",
      "[I 2024-11-23 21:52:19,371] Trial 10 finished with value: 0.30194069434877047 and parameters: {'classifier__iterations': 74, 'classifier__learning_rate': 0.06983637917642325, 'classifier__depth': 3, 'classifier__l2_leaf_reg': 2.2142350435498157}. Best is trial 6 with value: 0.38764595005382596.\n",
      "[I 2024-11-23 21:52:56,659] Trial 11 finished with value: 0.38508627902179055 and parameters: {'classifier__iterations': 55, 'classifier__learning_rate': 0.0918759451936913, 'classifier__depth': 5, 'classifier__l2_leaf_reg': 2.8498621122101}. Best is trial 6 with value: 0.38764595005382596.\n",
      "[I 2024-11-23 21:53:46,813] Trial 12 finished with value: 0.3887003488431147 and parameters: {'classifier__iterations': 59, 'classifier__learning_rate': 0.07516982680468555, 'classifier__depth': 6, 'classifier__l2_leaf_reg': 3.573956258642671}. Best is trial 12 with value: 0.3887003488431147.\n",
      "[I 2024-11-23 21:54:44,204] Trial 13 finished with value: 0.3987722380143607 and parameters: {'classifier__iterations': 69, 'classifier__learning_rate': 0.06750278443777788, 'classifier__depth': 6, 'classifier__l2_leaf_reg': 3.6964400458893834}. Best is trial 13 with value: 0.3987722380143607.\n",
      "[I 2024-11-23 21:55:39,935] Trial 14 finished with value: 0.3863934305442541 and parameters: {'classifier__iterations': 67, 'classifier__learning_rate': 0.06603206120009945, 'classifier__depth': 6, 'classifier__l2_leaf_reg': 3.8132537990104556}. Best is trial 13 with value: 0.3987722380143607.\n",
      "[I 2024-11-23 21:56:26,161] Trial 15 finished with value: 0.32507401556215954 and parameters: {'classifier__iterations': 45, 'classifier__learning_rate': 0.06840938748625625, 'classifier__depth': 6, 'classifier__l2_leaf_reg': 4.462266596772226}. Best is trial 13 with value: 0.3987722380143607.\n",
      "[I 2024-11-23 21:57:16,809] Trial 16 finished with value: 0.38474424033702176 and parameters: {'classifier__iterations': 64, 'classifier__learning_rate': 0.07792981190876914, 'classifier__depth': 5, 'classifier__l2_leaf_reg': 3.439432932941059}. Best is trial 13 with value: 0.3987722380143607.\n",
      "[I 2024-11-23 21:58:31,293] Trial 17 finished with value: 0.38258092833743923 and parameters: {'classifier__iterations': 74, 'classifier__learning_rate': 0.058195962161720564, 'classifier__depth': 6, 'classifier__l2_leaf_reg': 4.347375781450073}. Best is trial 13 with value: 0.3987722380143607.\n",
      "[I 2024-11-23 21:59:16,685] Trial 18 finished with value: 0.3686724349613715 and parameters: {'classifier__iterations': 57, 'classifier__learning_rate': 0.07967264682076419, 'classifier__depth': 5, 'classifier__l2_leaf_reg': 3.5447563060081437}. Best is trial 13 with value: 0.3987722380143607.\n",
      "[I 2024-11-23 22:00:04,592] Trial 19 finished with value: 0.27905024700655284 and parameters: {'classifier__iterations': 43, 'classifier__learning_rate': 0.055883124359481555, 'classifier__depth': 6, 'classifier__l2_leaf_reg': 3.293079853901126}. Best is trial 13 with value: 0.3987722380143607.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__iterations': 69, 'classifier__learning_rate': 0.06750278443777788, 'classifier__depth': 6, 'classifier__l2_leaf_reg': 3.6964400458893834}\n",
      "Test Accuracy: 0.8492469384882466\n",
      "F1 Score: 0.3948012808438501\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.98      0.91     17359\n",
      "           1       0.77      0.27      0.39      3954\n",
      "\n",
      "    accuracy                           0.85     21313\n",
      "   macro avg       0.81      0.62      0.65     21313\n",
      "weighted avg       0.84      0.85      0.82     21313\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CatBoost\n",
    "catboost_param_distributions = {\n",
    "    \"classifier__iterations\": optuna.distributions.IntDistribution(30, 100),    # Fewer iterations\n",
    "    \"classifier__learning_rate\": optuna.distributions.FloatDistribution(0.005, 0.1),  # Smaller learning rates\n",
    "    \"classifier__depth\": optuna.distributions.IntDistribution(2, 6),            # Shallower trees\n",
    "    \"classifier__l2_leaf_reg\": optuna.distributions.FloatDistribution(1, 5),    # Regularization strength\n",
    "}\n",
    "\n",
    "catboost_model, catboost_acc = train_model_with_optuna(\n",
    "    model=CatBoostClassifier(verbose=0, random_state=314),\n",
    "    param_distributions=catboost_param_distributions,\n",
    "    X_train_embeddings=X_train_embeddings,\n",
    "    y_train=y_train,\n",
    "    X_test_embeddings=X_test_embeddings,\n",
    "    y_test=y_test,\n",
    "    n_jobs=1,\n",
    ")\n",
    "best_models.append((\"catboost\", catboost_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf053c75-cc3a-4b62-a136-5fa0b8a52bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier Test Accuracy: 0.8685309435555764\n",
      "Stacking Classifier F1 Score: 0.5757116898849183\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92     17359\n",
      "           1       0.72      0.48      0.58      3954\n",
      "\n",
      "    accuracy                           0.87     21313\n",
      "   macro avg       0.80      0.72      0.75     21313\n",
      "weighted avg       0.86      0.87      0.86     21313\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stacking the best models\n",
    "stacked_classifier = StackingClassifier(\n",
    "    estimators=best_models,\n",
    "    final_estimator=GradientBoostingClassifier(random_state=314),\n",
    "    cv=5,\n",
    ")\n",
    "\n",
    "\n",
    "stacked_classifier.fit(X_train_embeddings, y_train)\n",
    "y_pred = stacked_classifier.predict(X_test_embeddings)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Stacking Classifier Test Accuracy: {acc}\")\n",
    "print(f\"Stacking Classifier F1 Score: {f1}\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2caa3fe-912f-4b07-a81d-c2d8bf4120f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
